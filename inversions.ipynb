{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values, find_dotenv\n",
    "import os\n",
    "from datacleaning.functions import filter_by_granularity\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.eval_measures import rmse, aic\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path parameters\n",
    "config = dotenv_values(find_dotenv())\n",
    "path_rawdata = os.path.abspath(config[\"RAWDATA\"]) + '\\\\'\n",
    "path_cleandata = os.path.abspath(config[\"CLEANDATA\"]) + '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my data\n",
    "bea_products = pd.read_pickle(path_cleandata + 'BEA_PCE.pkl')\n",
    "mergeddata = pd.read_pickle(path_cleandata + 'BEA6_naics6_merged.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are by product (as in the original BEA tables)\n",
    "\n",
    "beadata = filter_by_granularity(bea_products, target_granularity=6)\n",
    "beadata['product'] = beadata['product'].str.lstrip()\n",
    "\n",
    "prices = beadata[['product', 'date', 'priceindex']]\n",
    "expenditures = beadata[['product', 'date', 'expenditures']]\n",
    "\n",
    "prices.to_pickle(path_cleandata + 'firstinversion//prices.pkl')\n",
    "expenditures.to_pickle(path_cleandata + 'firstinversion//expenditures.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create io matrix: \n",
    "\n",
    "iomatrix_long = mergeddata[['product_I', 'product_O', 'IO_value']]\n",
    "iomatrix_wide = iomatrix_long.pivot_table(index='product_I', columns='product_O', values='IO_value', aggfunc='mean')\n",
    "iomatrix_wide.to_pickle(path_cleandata + 'firstinversion//iomatrix.pkl')\n",
    "\n",
    "# fill nans in another copy to use for inversion\n",
    "iomatrix_wide_fillna = iomatrix_wide.fillna(value=0)\n",
    "\n",
    "# save\n",
    "iomatrix_wide_fillna.to_pickle(path_cleandata + 'firstinversion//iomatrix_fillna.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EmilyFu\\AppData\\Local\\Temp\\ipykernel_5904\\2641519899.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  residuals = pd.concat([residuals, product_residuals])\n"
     ]
    }
   ],
   "source": [
    "# run vars, get resid\n",
    "\n",
    "# use the list of I products\n",
    "lags = 8\n",
    "residuals = pd.DataFrame(columns=['date', 'product', 'resid_price', 'resid_quantity'])\n",
    "\n",
    "to_run = list(set(beadata[(beadata['quantityindex'].notnull()) & (beadata['priceindex'].notnull())]['product']))\n",
    "for product in to_run:\n",
    "    # filter for product\n",
    "    tovar = beadata[beadata['product'] == product][['date', 'priceindex', 'quantityindex']]\n",
    "    # datetimeindex\n",
    "    tovar = tovar.set_index('date')\n",
    "    # zeros for index values should be removed!!\n",
    "    tovar = tovar.loc[~(tovar==0).any(axis=1)]\n",
    "\n",
    "    # using first differences\n",
    "    tovar['priceindex'] = np.log(tovar['priceindex']).diff()\n",
    "    tovar['quantityindex'] = np.log(tovar['quantityindex']).diff()\n",
    "    # drop nans for model\n",
    "    tovar.dropna(inplace=True)\n",
    "\n",
    "    model = VAR(tovar.asfreq('Q-OCT'))\n",
    "    result = model.fit(lags)\n",
    "\n",
    "    # print(product)\n",
    "    # print('AIC : ', result.aic)\n",
    "    # print('BIC : ', result.bic)\n",
    "    # print('FPE : ', result.fpe)\n",
    "    # print('HQIC: ', result.hqic)\n",
    "\n",
    "    # residuals\n",
    "    product_residuals = result.resid.reset_index()\n",
    "    product_residuals['product'] = product\n",
    "    product_residuals.rename(columns={'priceindex': 'resid_price', 'quantityindex': 'resid_quantity'}, inplace=True)\n",
    "    residuals = pd.concat([residuals, product_residuals])\n",
    "    \n",
    "# calculate expenditure residual\n",
    "residuals['resid_expenditure_calculated'] = residuals['resid_price'] * residuals['resid_quantity']\n",
    "\n",
    "# supply vs demand driven\n",
    "residuals['majority_demand'] = ((residuals['resid_price'] >= 0) & (residuals['resid_quantity'] >= 0) | (residuals['resid_price'] <= 0) & (residuals['resid_quantity'] <= 0)).astype(int)\n",
    "residuals['majority_supply'] = ((residuals['resid_price'] * residuals['resid_quantity']) < 0).astype(int)\n",
    "\n",
    "# save\n",
    "residuals = residuals.sort_values('product')\n",
    "residuals.to_pickle(path_cleandata + 'firstinversion//residuals.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER\n",
    "\n",
    "# first, i need products that actually have a residual at each date\n",
    "# total number of unique dates\n",
    "total_dates = residuals['date'].nunique()\n",
    "# group by product and count the number of unique dates for each product\n",
    "product_dates_count = residuals.groupby('product')['date'].nunique()\n",
    "# filter products that appear at all dates\n",
    "products_appear_all_dates = product_dates_count[product_dates_count == total_dates].index.tolist()\n",
    "\n",
    "# next, i need products that show up as both buyers and sellers\n",
    "# list of sellers\n",
    "inputproducts = list(iomatrix_wide_fillna.index)\n",
    "# list of buyers\n",
    "outputproducts = list(iomatrix_wide_fillna.columns)\n",
    "\n",
    "# get the intersection of these lists\n",
    "products_to_include = list(set(products_appear_all_dates) & set(inputproducts) & set(outputproducts))\n",
    "\n",
    "# filter I-O table and residuals\n",
    "iomatrix_wide_fillna.drop(columns=[col for col in iomatrix_wide_fillna.columns if col not in products_to_include], inplace=True)\n",
    "iomatrix_wide_fillna.drop(index=[idx for idx in iomatrix_wide_fillna.index if idx not in products_to_include], inplace=True)\n",
    "residuals = residuals[residuals['product'].isin(products_to_include)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose of the I-O matrix so that rows are buyers and columns are sellers\n",
    "iomatrix_fillna_T = iomatrix_wide_fillna.T\n",
    "\n",
    "# grouping sums by buyer/seller\n",
    "io_sum_buyers = iomatrix_fillna_T.sum(axis=1) # sum by columns so that each buyer (index) has its total purchases\n",
    "io_sum_sellers = iomatrix_fillna_T.sum(axis=0) # sum by rows so that each seller (column) has its total sales\n",
    "\n",
    "# final demand vector\n",
    "fd = iomatrix_wide['Personal consumption expenditures']\n",
    "fd = fd.loc[products_to_include].fillna(value=0)\n",
    "\n",
    "# quantity and price residuals\n",
    "priceresiduals = residuals[['date', 'product', 'resid_price']]\n",
    "quantityresiduals = residuals[['date', 'product', 'resid_quantity']]\n",
    "\n",
    "#  I-O matrix INTERMEDIATE COST SHARES\n",
    "intermediate_costshares = pd.DataFrame(index=iomatrix_wide_fillna.index, columns=iomatrix_wide_fillna.columns)\n",
    "for col in iomatrix_wide_fillna.columns:\n",
    "    intermediate_costshares[col] = iomatrix_wide_fillna[col] / io_sum_buyers[col]\n",
    "\n",
    "# I-O matrix INTERMEDIATE SALES SHARES\n",
    "intermediate_salesshares = pd.Series(index=iomatrix_wide_fillna.index)\n",
    "for col in iomatrix_wide_fillna.columns:\n",
    "    hello = io_sum_sellers[col] / (io_sum_buyers[col] + fd[col])\n",
    "    intermediate_salesshares[col] = io_sum_sellers[col] / (io_sum_buyers[col] + fd[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EmilyFu\\AppData\\Local\\Temp\\ipykernel_5904\\999376705.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  priceresiduals_adjusted = pd.concat([priceresiduals_adjusted, priceresiduals_adjusted_date], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# dates!\n",
    "dates = set(set(priceresiduals['date'].unique()) & set(quantityresiduals['date'].unique()))\n",
    "\n",
    "# I-O adjusted price residual\n",
    "\n",
    "priceresiduals_adjusted = pd.DataFrame(columns=['date', 'product', 'resid_price_adjusted'])\n",
    "for date in dates:\n",
    "    # filter priceresiduals for the current date\n",
    "    priceresiduals_date = priceresiduals[priceresiduals['date'] == date].set_index('product')[['resid_price']]\n",
    "    priceresiduals_date = priceresiduals_date.sort_index()\n",
    "\n",
    "    # Create the diagonal matrix from intermediate_salesshares\n",
    "    diag_matrix = np.diag(intermediate_salesshares)\n",
    "    \n",
    "    # Calculate the adjustment matrix: (I - diag(intermediate_salesshares) * intermediate_costshares)^(-1)\n",
    "    adjustment_matrix = np.linalg.inv(np.identity(len(intermediate_costshares)) - (diag_matrix @ intermediate_costshares))\n",
    "\n",
    "    # Calculate priceresiduals_adjusted for the current date\n",
    "    priceresiduals_adjusted_date = adjustment_matrix @ priceresiduals_date\n",
    "    # set some columns to append\n",
    "    priceresiduals_adjusted_date['date'] = date\n",
    "    priceresiduals_adjusted_date['product'] = priceresiduals_date.index\n",
    "    priceresiduals_adjusted_date.rename(columns={'resid_price': 'resid_price_adjusted'}, inplace=True)\n",
    "    # append\n",
    "    priceresiduals_adjusted = pd.concat([priceresiduals_adjusted, priceresiduals_adjusted_date], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EmilyFu\\AppData\\Local\\Temp\\ipykernel_5904\\1392671200.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  quantityresiduals_adjusted = pd.concat([quantityresiduals_adjusted, quantityresiduals_adjusted_date], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# I-O adjusted quantity residual\n",
    "\n",
    "quantityresiduals_adjusted = pd.DataFrame(columns=['date', 'product', 'resid_quantity_adjusted'])\n",
    "for date in dates:\n",
    "    # filter priceresiduals for the current date\n",
    "    priceresiduals_date = priceresiduals[priceresiduals['date'] == date].set_index('product')[['resid_price']]\n",
    "    priceresiduals_date = priceresiduals_date.sort_index()\n",
    "\n",
    "    # filter quantityresiduals for the current date\n",
    "    quantityresiduals_date = quantityresiduals[quantityresiduals['date'] == date].set_index('product')[['resid_quantity']]\n",
    "    quantityresiduals_date = quantityresiduals_date.sort_index()\n",
    "\n",
    "    # price * quantity\n",
    "    pricequantity_date = priceresiduals_date['resid_price'] * quantityresiduals_date['resid_quantity']\n",
    "\n",
    "    # filter adjusted price residuals for the current date\n",
    "    priceresiduals_adjusted_date = priceresiduals_adjusted[priceresiduals_adjusted['date'] == date].set_index('product')[['resid_price_adjusted']]\n",
    "    priceresiduals_adjusted_date = priceresiduals_adjusted_date.sort_index()\n",
    "\n",
    "    # Create the diagonal matrix from intermediate_salesshares\n",
    "    diag_matrix = np.diag(intermediate_salesshares)\n",
    "    \n",
    "    # calculate \"sales\" in each sector\n",
    "    sales_date = np.linalg.inv(np.identity(len(intermediate_costshares)) - (intermediate_costshares.T @ diag_matrix)) @ pricequantity_date\n",
    "\n",
    "    # Calculate quantityresiduals_adjusted for the current date\n",
    "    quantityresiduals_adjusted_date = sales_date / priceresiduals_adjusted_date['resid_price_adjusted']\n",
    "    quantityresiduals_adjusted_date = quantityresiduals_adjusted_date.reset_index()\n",
    "    # set some columns to append\n",
    "    quantityresiduals_adjusted_date['date'] = date\n",
    "    quantityresiduals_adjusted_date.rename(columns={'resid_price_adjusted': 'resid_quantity_adjusted'}, inplace=True)\n",
    "    # append\n",
    "    quantityresiduals_adjusted = pd.concat([quantityresiduals_adjusted, quantityresiduals_adjusted_date], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between adjustment and original price residual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
